{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Coding/segmentation\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbinhnd-cse\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "from runner import SegmentationModel\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentationModel(\n",
       "  (model): AttentionUNet(\n",
       "    (MaxPool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (Conv1): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv2): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv3): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv4): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv5): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Up5): UpConv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att5): AttentionBlock(\n",
       "      (W_gate): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (UpConv5): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Up4): UpConv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att4): AttentionBlock(\n",
       "      (W_gate): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (UpConv4): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Up3): UpConv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att3): AttentionBlock(\n",
       "      (W_gate): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (UpConv3): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Up2): UpConv(\n",
       "      (up): Sequential(\n",
       "        (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Att2): AttentionBlock(\n",
       "      (W_gate): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (W_x): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (psi): Sequential(\n",
       "        (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (UpConv2): ConvBlock(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (Conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (loss_function): FocalLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegmentationModel.load_from_checkpoint(\"/mnt/d/Coding/segmentation/checkpoints/epoch=24-step=2850.ckpt\")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "gt_df = pd.read_csv(\"data/kaggle/subset_gt.csv\")\n",
    "val_df = gt_df[gt_df[\"group\"] == \"kidney_3_dense\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = val_df[\"id\"].values\n",
    "image_files = list(range(len(val_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>1706</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      height  width\n",
       "2279    1706   1510\n",
       "2280    1706   1510\n",
       "2281    1706   1510\n",
       "2282    1706   1510\n",
       "2283    1706   1510\n",
       "...      ...    ...\n",
       "2775    1706   1510\n",
       "2776    1706   1510\n",
       "2777    1706   1510\n",
       "2778    1706   1510\n",
       "2779    1706   1510\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[[\"height\", \"width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "import cv2\n",
    "from data import H5ImageProcess, subset_preprocess_mask\n",
    "\n",
    "\n",
    "h5_image_process = H5ImageProcess(\"data/kaggle/kidney_3_dense.hdf5\")\n",
    "\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_ids, image_files):\n",
    "        self.image_ids = image_ids\n",
    "        self.image_files = image_files\n",
    "        self.resize_fn = Resize((256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_file = self.image_files[idx]\n",
    "        image = h5_image_process.preprocess_image_val(image_file)\n",
    "        h, w = 1706, 1510\n",
    "        image = self.resize_fn(image)\n",
    "        return image_id, image, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(image_ids=image_ids, image_files=image_files)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id, image, hs, ws in test_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    if rle=='':\n",
    "        rle = '1 0'\n",
    "    return rle\n",
    "\n",
    "\n",
    "def remove_small_objects(mask, min_size):\n",
    "    # find all connected components (labels)\n",
    "    num_label, label, stats, centroid = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
    "    # create a mask where small objects are removed\n",
    "    processed = np.zeros_like(mask)\n",
    "    for l in range(1, num_label):\n",
    "        if stats[l, cv2.CC_STAT_AREA] >= min_size:\n",
    "            processed[label == l] = 1\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_ids = []\n",
    "rles = []\n",
    "device = model.device\n",
    "\n",
    "for image_id, image, hs, ws in test_dataloader:\n",
    "    image_ids.extend(image_id)\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        preds = model.model(image)\n",
    "        preds = (nn.Sigmoid()(preds)>0.5).double()\n",
    "    for pred, h, w in zip(preds.data.cpu(), hs, ws):\n",
    "        reverse_resize = Resize((h, w), interpolation=cv2.INTER_NEAREST)\n",
    "        pred = reverse_resize(pred)\n",
    "        clean_pred = remove_small_objects(pred.numpy().squeeze().astype(np.uint8), 10)\n",
    "        rles.append(rle_encode(clean_pred))\n",
    "\n",
    "submision_df = pd.DataFrame({\"id\": image_ids, \"rle\": rles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Groundtruth:\n",
    "    id: List[str] = field(default_factory=list)\n",
    "    rle: List[str] = field(default_factory=list)\n",
    "    group: List[str] = field(default_factory=list)\n",
    "    slice: List[int] = field(default_factory=list)\n",
    "    height: List[int] = field(default_factory=list)\n",
    "    width: List[int] = field(default_factory=list)\n",
    "    \n",
    "    def convert(self, tensor):\n",
    "        return [int(i) for i in tensor]\n",
    "    \n",
    "    def update(self, ids, rles, groups, slices, heights, widths):\n",
    "        self.id.extend(ids)\n",
    "        self.rle.extend(rles)\n",
    "        self.group.extend(groups)\n",
    "        self.slice.extend(self.convert(slices))\n",
    "        self.height.extend(self.convert(heights))\n",
    "        self.width.extend(self.convert(widths))\n",
    "        \n",
    "        \n",
    "@dataclass\n",
    "class Submission:\n",
    "    id: List[str] = field(default_factory=list)\n",
    "    rle: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def convert(self, tensor):\n",
    "        return [int(i) for i in tensor]\n",
    "    \n",
    "    def update(self, ids, rles):\n",
    "        self.id.extend(ids)\n",
    "        self.rle.extend(rles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_fn = Resize((256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def subset_preprocess_mask(lre, H=1303, W=912):\n",
    "    mask = rle_decode(lre, (H, W))\n",
    "    mask_tensor = torch.Tensor(mask)\n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.image_paths = list(range(len(df)))\n",
    "        self.label_paths = df[\"rle\"].values\n",
    "        self.group_names = df[\"group\"].values\n",
    "        self.slide_ids = df[\"slice\"].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.label_paths[idx]\n",
    "        group_name = self.group_names[idx]\n",
    "        slice_id = self.slide_ids[idx]\n",
    "        sample_id = f\"{group_name}_{slice_id}\"\n",
    "        \n",
    "        image = h5_image_process.preprocess_image_val(image_path)\n",
    "        height, width = image.shape[1], image.shape[2]\n",
    "        \n",
    "        mask = subset_preprocess_mask(mask_path, 1706, 1510)\n",
    "        image = resize_fn(image)\n",
    "        return sample_id, image, mask, group_name, slice_id, height, width\n",
    "\n",
    "\n",
    "val_dataset = ValDataset(val_df)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:21<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "gt_dicts = Groundtruth()\n",
    "sub_dicts = Submission()\n",
    "# submission_dicts = []\n",
    "for batch in tqdm(val_dataloader):\n",
    "    sample_id, image, mask, group_name, slide_id, height, width = batch\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        preds = model.model(image)\n",
    "        preds = (nn.Sigmoid()(preds)>0.5).double()\n",
    "    \n",
    "    rles = []\n",
    "    for pred, h, w in zip(preds.data.cpu(), height, width):\n",
    "        reverse_resize = Resize((1706, 1510), interpolation=cv2.INTER_NEAREST)\n",
    "        pred = reverse_resize(pred)\n",
    "        clean_pred = remove_small_objects(pred.numpy().squeeze().astype(np.uint8), 10)\n",
    "        rles.append(rle_encode(clean_pred))\n",
    "    gt_rles = []\n",
    "    for m in mask:\n",
    "        gt_rles.append(rle_encode(m.numpy().astype(\"uint8\")))\n",
    "    \n",
    "    height = [1706] * len(height)\n",
    "    width = [1510] * len(width)\n",
    "    gt_dicts.update(sample_id, gt_rles, group_name, slide_id, height, width)\n",
    "    sub_dicts.update(sample_id, rles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = pd.DataFrame(asdict(gt_dicts))\n",
    "sub_df = pd.DataFrame(asdict(sub_dicts))\n",
    "gt_df = gt_df.sort_values(by=\"slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'393221 6 394731 6 396241 6 397751 6 399261 6 400771 6 402281 6 474773 11 476283 11 477793 11 479303 11 480813 11 482323 11 483833 6 485343 6 486853 6 488363 6 489873 6 491383 6 492893 6 494403 6 495913 6 497423 6 498933 6 500443 6 501953 6 503463 6 504973 11 506483 11 507993 11 509503 11 511013 11 512523 11 514027 17 515537 17 517047 17 518557 17 520067 17 521577 17 523087 17 524603 6 526113 6 527623 6 529133 6 530643 6 532153 6 533663 6 867738 12 869248 12 870758 12 872268 12 873778 12 875288 12 1037926 6 1039436 6 1040946 6 1042456 6 1043966 6 1045476 6 1046986 6 1048490 18 1050000 18 1051510 18 1053020 18 1054530 18 1056040 18 1057544 18 1059054 18 1060564 18 1062074 18 1063584 18 1065094 18 1066604 18 1068120 6 1069630 6 1071140 6 1072650 6 1074160 6 1075670 6 1077180 6 1128650 18 1130160 18 1131670 18 1133180 18 1134690 18 1136200 18 1137710 18 1139214 24 1140724 24 1142234 24 1143744 24 1145254 24 1146764 24 1148274 18 1149784 18 1151294 18 1152804 18 1154314 18 1155824 18 1157334 18 1349257 6 1350767 6 1352277 6 1353787 6 1355297 6 1356807 6 1358317 6 1359827 6 1361337 6 1362847 6 1364357 6 1365867 6 1367377 6 1368887 6 1530593 24 1530676 5 1532103 24 1532186 5 1533613 24 1533696 5 1535123 24 1535206 5 1536633 24 1536716 5 1538143 24 1538226 5 1539653 24 1539736 5 1541157 24 1541222 6 1541246 11 1542667 24 1542732 6 1542756 11 1544177 24 1544242 6 1544266 11 1545687 24 1545752 6 1545776 11 1547197 24 1547262 6 1547286 11 1548707 24 1548772 6 1548796 11 1550217 24 1550282 6 1550306 11 1793250 6 1794760 6 1796270 6 1797780 6 1799290 6 1800800 6 1802310 12 1803820 12 1805330 12 1806840 12 1808350 12 1809860 12 1811370 12 1812880 6 1814390 6 1815900 6 1817410 6 1818920 6 1820430 6 1821940 6'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[sub_df[\"id\"]==\"kidney_3_dense_100\"][\"rle\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df_real = pd.read_csv(\"/mnt/c/Users/binhn/Downloads/gt_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "sub_image = Image.fromarray(rle_decode(sub_df[sub_df[\"id\"]==\"kidney_3_dense_100\"][\"rle\"].values[0], shape=(1706,1510))*255)\n",
    "gt_image = Image.fromarray(rle_decode(gt_df.iloc[100][\"rle\"], shape=(1706,1510))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_df[\"rle\"] = gt_df_real[\"rle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "score(sub_df, gt_df, \"id\", \"rle\", image_id_column_name=\"group\", slice_id_column_name=\"slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
